{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer \n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".\\DATA\\wine.csv\")\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# deal with missing data\n",
    "Imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "Imputer.fit(X[:, :])\n",
    "X[:, :] = Imputer.transform(X[:, :])\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try linearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.31108338963040694\n"
     ]
    }
   ],
   "source": [
    "# print acc\n",
    "acc = regressor.score(X_test, y_test)\n",
    "print(f\"acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add const\n",
    "X_train = np.append(arr=np.ones((len(X_train), 1)).astype(int), values=X_train, axis=1)\n",
    "# try to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.369</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.364</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   67.39</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 19 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>1.66e-118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:30:19</td>     <th>  Log-Likelihood:    </th> <td> -1266.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1279</td>      <th>  AIC:               </th> <td>   2556.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1267</td>      <th>  BIC:               </th> <td>   2618.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   23.8636</td> <td>   23.945</td> <td>    0.997</td> <td> 0.319</td> <td>  -23.113</td> <td>   70.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0249</td> <td>    0.029</td> <td>    0.856</td> <td> 0.392</td> <td>   -0.032</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -1.1513</td> <td>    0.136</td> <td>   -8.470</td> <td> 0.000</td> <td>   -1.418</td> <td>   -0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1803</td> <td>    0.166</td> <td>   -1.087</td> <td> 0.277</td> <td>   -0.506</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0147</td> <td>    0.017</td> <td>    0.869</td> <td> 0.385</td> <td>   -0.018</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -2.0441</td> <td>    0.479</td> <td>   -4.263</td> <td> 0.000</td> <td>   -2.985</td> <td>   -1.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0052</td> <td>    0.002</td> <td>    2.072</td> <td> 0.038</td> <td>    0.000</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0041</td> <td>    0.001</td> <td>   -4.846</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  -19.3864</td> <td>   24.443</td> <td>   -0.793</td> <td> 0.428</td> <td>  -67.339</td> <td>   28.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.4684</td> <td>    0.218</td> <td>   -2.153</td> <td> 0.032</td> <td>   -0.895</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.9447</td> <td>    0.126</td> <td>    7.491</td> <td> 0.000</td> <td>    0.697</td> <td>    1.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.2614</td> <td>    0.030</td> <td>    8.733</td> <td> 0.000</td> <td>    0.203</td> <td>    0.320</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>29.228</td> <th>  Durbin-Watson:     </th> <td>   2.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  39.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.254</td> <th>  Prob(JB):          </th> <td>2.57e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.695</td> <th>  Cond. No.          </th> <td>1.12e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.12e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.369\n",
       "Model:                            OLS   Adj. R-squared:                  0.364\n",
       "Method:                 Least Squares   F-statistic:                     67.39\n",
       "Date:                Thu, 19 Nov 2020   Prob (F-statistic):          1.66e-118\n",
       "Time:                        10:30:19   Log-Likelihood:                -1266.0\n",
       "No. Observations:                1279   AIC:                             2556.\n",
       "Df Residuals:                    1267   BIC:                             2618.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         23.8636     23.945      0.997      0.319     -23.113      70.840\n",
       "x1             0.0249      0.029      0.856      0.392      -0.032       0.082\n",
       "x2            -1.1513      0.136     -8.470      0.000      -1.418      -0.885\n",
       "x3            -0.1803      0.166     -1.087      0.277      -0.506       0.145\n",
       "x4             0.0147      0.017      0.869      0.385      -0.018       0.048\n",
       "x5            -2.0441      0.479     -4.263      0.000      -2.985      -1.103\n",
       "x6             0.0052      0.002      2.072      0.038       0.000       0.010\n",
       "x7            -0.0041      0.001     -4.846      0.000      -0.006      -0.002\n",
       "x8           -19.3864     24.443     -0.793      0.428     -67.339      28.567\n",
       "x9            -0.4684      0.218     -2.153      0.032      -0.895      -0.042\n",
       "x10            0.9447      0.126      7.491      0.000       0.697       1.192\n",
       "x11            0.2614      0.030      8.733      0.000       0.203       0.320\n",
       "==============================================================================\n",
       "Omnibus:                       29.228   Durbin-Watson:                   2.049\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               39.562\n",
       "Skew:                          -0.254   Prob(JB):                     2.57e-09\n",
       "Kurtosis:                       3.695   Cond. No.                     1.12e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.12e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "X_opt = X_train[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]\n",
    "X_opt = np.array(X_opt, dtype=float)\n",
    "regressor_OLS = sm.OLS(endog=y_train, exog=X_opt).fit()\n",
    "regressor_OLS.summary()    # drop x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.369</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.364</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   74.09</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 19 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>2.56e-119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:30:19</td>     <th>  Log-Likelihood:    </th> <td> -1266.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1279</td>      <th>  AIC:               </th> <td>   2555.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1268</td>      <th>  BIC:               </th> <td>   2611.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    4.8800</td> <td>    0.694</td> <td>    7.036</td> <td> 0.000</td> <td>    3.519</td> <td>    6.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0068</td> <td>    0.018</td> <td>    0.377</td> <td> 0.707</td> <td>   -0.029</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -1.1631</td> <td>    0.135</td> <td>   -8.609</td> <td> 0.000</td> <td>   -1.428</td> <td>   -0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1821</td> <td>    0.166</td> <td>   -1.098</td> <td> 0.273</td> <td>   -0.508</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0067</td> <td>    0.014</td> <td>    0.496</td> <td> 0.620</td> <td>   -0.020</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -2.0770</td> <td>    0.478</td> <td>   -4.349</td> <td> 0.000</td> <td>   -3.014</td> <td>   -1.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0054</td> <td>    0.002</td> <td>    2.181</td> <td> 0.029</td> <td>    0.001</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0042</td> <td>    0.001</td> <td>   -4.950</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.5683</td> <td>    0.177</td> <td>   -3.201</td> <td> 0.001</td> <td>   -0.916</td> <td>   -0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.9190</td> <td>    0.122</td> <td>    7.541</td> <td> 0.000</td> <td>    0.680</td> <td>    1.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.2794</td> <td>    0.019</td> <td>   14.367</td> <td> 0.000</td> <td>    0.241</td> <td>    0.318</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>26.932</td> <th>  Durbin-Watson:     </th> <td>   2.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  35.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.244</td> <th>  Prob(JB):          </th> <td>1.66e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.660</td> <th>  Cond. No.          </th> <td>2.41e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.41e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.369\n",
       "Model:                            OLS   Adj. R-squared:                  0.364\n",
       "Method:                 Least Squares   F-statistic:                     74.09\n",
       "Date:                Thu, 19 Nov 2020   Prob (F-statistic):          2.56e-119\n",
       "Time:                        10:30:19   Log-Likelihood:                -1266.3\n",
       "No. Observations:                1279   AIC:                             2555.\n",
       "Df Residuals:                    1268   BIC:                             2611.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.8800      0.694      7.036      0.000       3.519       6.241\n",
       "x1             0.0068      0.018      0.377      0.707      -0.029       0.042\n",
       "x2            -1.1631      0.135     -8.609      0.000      -1.428      -0.898\n",
       "x3            -0.1821      0.166     -1.098      0.273      -0.508       0.143\n",
       "x4             0.0067      0.014      0.496      0.620      -0.020       0.033\n",
       "x5            -2.0770      0.478     -4.349      0.000      -3.014      -1.140\n",
       "x6             0.0054      0.002      2.181      0.029       0.001       0.010\n",
       "x7            -0.0042      0.001     -4.950      0.000      -0.006      -0.003\n",
       "x8            -0.5683      0.177     -3.201      0.001      -0.916      -0.220\n",
       "x9             0.9190      0.122      7.541      0.000       0.680       1.158\n",
       "x10            0.2794      0.019     14.367      0.000       0.241       0.318\n",
       "==============================================================================\n",
       "Omnibus:                       26.932   Durbin-Watson:                   2.048\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.824\n",
       "Skew:                          -0.244   Prob(JB):                     1.66e-08\n",
       "Kurtosis:                       3.660   Cond. No.                     2.41e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.41e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 \n",
    "X_opt = X_train[:, [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11]]\n",
    "X_opt = np.array(X_opt, dtype=float)\n",
    "\n",
    "regressor_OLS = sm.OLS(endog=y_train, exog=X_opt).fit()\n",
    "regressor_OLS.summary()    # drop x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.369</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.364</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   82.36</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 19 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>2.94e-120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:30:19</td>     <th>  Log-Likelihood:    </th> <td> -1266.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1279</td>      <th>  AIC:               </th> <td>   2553.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1269</td>      <th>  BIC:               </th> <td>   2604.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    5.0542</td> <td>    0.517</td> <td>    9.778</td> <td> 0.000</td> <td>    4.040</td> <td>    6.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -1.1507</td> <td>    0.131</td> <td>   -8.785</td> <td> 0.000</td> <td>   -1.408</td> <td>   -0.894</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.1475</td> <td>    0.138</td> <td>   -1.068</td> <td> 0.286</td> <td>   -0.418</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0071</td> <td>    0.014</td> <td>    0.520</td> <td> 0.603</td> <td>   -0.020</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -2.1272</td> <td>    0.459</td> <td>   -4.639</td> <td> 0.000</td> <td>   -3.027</td> <td>   -1.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0055</td> <td>    0.002</td> <td>    2.220</td> <td> 0.027</td> <td>    0.001</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0043</td> <td>    0.001</td> <td>   -5.274</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.6040</td> <td>    0.150</td> <td>   -4.026</td> <td> 0.000</td> <td>   -0.898</td> <td>   -0.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.9224</td> <td>    0.121</td> <td>    7.592</td> <td> 0.000</td> <td>    0.684</td> <td>    1.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2784</td> <td>    0.019</td> <td>   14.467</td> <td> 0.000</td> <td>    0.241</td> <td>    0.316</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>26.435</td> <th>  Durbin-Watson:     </th> <td>   2.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  34.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.242</td> <th>  Prob(JB):          </th> <td>2.61e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.649</td> <th>  Cond. No.          </th> <td>1.80e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.8e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.369\n",
       "Model:                            OLS   Adj. R-squared:                  0.364\n",
       "Method:                 Least Squares   F-statistic:                     82.36\n",
       "Date:                Thu, 19 Nov 2020   Prob (F-statistic):          2.94e-120\n",
       "Time:                        10:30:19   Log-Likelihood:                -1266.4\n",
       "No. Observations:                1279   AIC:                             2553.\n",
       "Df Residuals:                    1269   BIC:                             2604.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.0542      0.517      9.778      0.000       4.040       6.068\n",
       "x1            -1.1507      0.131     -8.785      0.000      -1.408      -0.894\n",
       "x2            -0.1475      0.138     -1.068      0.286      -0.418       0.123\n",
       "x3             0.0071      0.014      0.520      0.603      -0.020       0.034\n",
       "x4            -2.1272      0.459     -4.639      0.000      -3.027      -1.228\n",
       "x5             0.0055      0.002      2.220      0.027       0.001       0.010\n",
       "x6            -0.0043      0.001     -5.274      0.000      -0.006      -0.003\n",
       "x7            -0.6040      0.150     -4.026      0.000      -0.898      -0.310\n",
       "x8             0.9224      0.121      7.592      0.000       0.684       1.161\n",
       "x9             0.2784      0.019     14.467      0.000       0.241       0.316\n",
       "==============================================================================\n",
       "Omnibus:                       26.435   Durbin-Watson:                   2.048\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               34.924\n",
       "Skew:                          -0.242   Prob(JB):                     2.61e-08\n",
       "Kurtosis:                       3.649   Cond. No.                     1.80e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.8e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3\n",
    "X_opt = X_train[:, [0, 2, 3, 4, 5, 6, 7, 9, 10, 11]]\n",
    "X_opt = np.array(X_opt, dtype=float)\n",
    "\n",
    "regressor_OLS = sm.OLS(endog=y_train, exog=X_opt).fit()\n",
    "regressor_OLS.summary()    # drop x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.369</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.365</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   92.68</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 19 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>3.38e-121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:30:19</td>     <th>  Log-Likelihood:    </th> <td> -1266.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1279</td>      <th>  AIC:               </th> <td>   2551.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1270</td>      <th>  BIC:               </th> <td>   2597.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    5.0603</td> <td>    0.517</td> <td>    9.795</td> <td> 0.000</td> <td>    4.047</td> <td>    6.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -1.1456</td> <td>    0.131</td> <td>   -8.773</td> <td> 0.000</td> <td>   -1.402</td> <td>   -0.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.1375</td> <td>    0.137</td> <td>   -1.006</td> <td> 0.315</td> <td>   -0.406</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -2.1171</td> <td>    0.458</td> <td>   -4.622</td> <td> 0.000</td> <td>   -3.016</td> <td>   -1.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0056</td> <td>    0.002</td> <td>    2.275</td> <td> 0.023</td> <td>    0.001</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0043</td> <td>    0.001</td> <td>   -5.250</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.6056</td> <td>    0.150</td> <td>   -4.039</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.9176</td> <td>    0.121</td> <td>    7.577</td> <td> 0.000</td> <td>    0.680</td> <td>    1.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.2794</td> <td>    0.019</td> <td>   14.599</td> <td> 0.000</td> <td>    0.242</td> <td>    0.317</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>25.199</td> <th>  Durbin-Watson:     </th> <td>   2.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  33.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.235</td> <th>  Prob(JB):          </th> <td>6.54e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.633</td> <th>  Cond. No.          </th> <td>1.80e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.8e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.369\n",
       "Model:                            OLS   Adj. R-squared:                  0.365\n",
       "Method:                 Least Squares   F-statistic:                     92.68\n",
       "Date:                Thu, 19 Nov 2020   Prob (F-statistic):          3.38e-121\n",
       "Time:                        10:30:19   Log-Likelihood:                -1266.5\n",
       "No. Observations:                1279   AIC:                             2551.\n",
       "Df Residuals:                    1270   BIC:                             2597.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.0603      0.517      9.795      0.000       4.047       6.074\n",
       "x1            -1.1456      0.131     -8.773      0.000      -1.402      -0.889\n",
       "x2            -0.1375      0.137     -1.006      0.315      -0.406       0.131\n",
       "x3            -2.1171      0.458     -4.622      0.000      -3.016      -1.219\n",
       "x4             0.0056      0.002      2.275      0.023       0.001       0.010\n",
       "x5            -0.0043      0.001     -5.250      0.000      -0.006      -0.003\n",
       "x6            -0.6056      0.150     -4.039      0.000      -0.900      -0.311\n",
       "x7             0.9176      0.121      7.577      0.000       0.680       1.155\n",
       "x8             0.2794      0.019     14.599      0.000       0.242       0.317\n",
       "==============================================================================\n",
       "Omnibus:                       25.199   Durbin-Watson:                   2.047\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               33.085\n",
       "Skew:                          -0.235   Prob(JB):                     6.54e-08\n",
       "Kurtosis:                       3.633   Cond. No.                     1.80e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.8e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "X_opt = X_train[:, [0, 2, 3, 5, 6, 7, 9, 10, 11]]\n",
    "X_opt = np.array(X_opt, dtype=float)\n",
    "\n",
    "regressor_OLS = sm.OLS(endog=y_train, exog=X_opt).fit()\n",
    "regressor_OLS.summary()    # drop x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.368</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.365</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   105.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 19 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>5.22e-122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:30:19</td>     <th>  Log-Likelihood:    </th> <td> -1267.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1279</td>      <th>  AIC:               </th> <td>   2550.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1271</td>      <th>  BIC:               </th> <td>   2591.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    4.8069</td> <td>    0.451</td> <td>   10.659</td> <td> 0.000</td> <td>    3.922</td> <td>    5.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -1.0823</td> <td>    0.114</td> <td>   -9.463</td> <td> 0.000</td> <td>   -1.307</td> <td>   -0.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -2.1919</td> <td>    0.452</td> <td>   -4.850</td> <td> 0.000</td> <td>   -3.078</td> <td>   -1.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0059</td> <td>    0.002</td> <td>    2.433</td> <td> 0.015</td> <td>    0.001</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0044</td> <td>    0.001</td> <td>   -5.460</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.5348</td> <td>    0.132</td> <td>   -4.040</td> <td> 0.000</td> <td>   -0.794</td> <td>   -0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.9091</td> <td>    0.121</td> <td>    7.525</td> <td> 0.000</td> <td>    0.672</td> <td>    1.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.2756</td> <td>    0.019</td> <td>   14.686</td> <td> 0.000</td> <td>    0.239</td> <td>    0.312</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>26.324</td> <th>  Durbin-Watson:     </th> <td>   2.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  34.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.243</td> <th>  Prob(JB):          </th> <td>3.13e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.642</td> <th>  Cond. No.          </th> <td>1.69e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.69e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.368\n",
       "Model:                            OLS   Adj. R-squared:                  0.365\n",
       "Method:                 Least Squares   F-statistic:                     105.8\n",
       "Date:                Thu, 19 Nov 2020   Prob (F-statistic):          5.22e-122\n",
       "Time:                        10:30:19   Log-Likelihood:                -1267.0\n",
       "No. Observations:                1279   AIC:                             2550.\n",
       "Df Residuals:                    1271   BIC:                             2591.\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          4.8069      0.451     10.659      0.000       3.922       5.692\n",
       "x1            -1.0823      0.114     -9.463      0.000      -1.307      -0.858\n",
       "x2            -2.1919      0.452     -4.850      0.000      -3.078      -1.305\n",
       "x3             0.0059      0.002      2.433      0.015       0.001       0.011\n",
       "x4            -0.0044      0.001     -5.460      0.000      -0.006      -0.003\n",
       "x5            -0.5348      0.132     -4.040      0.000      -0.794      -0.275\n",
       "x6             0.9091      0.121      7.525      0.000       0.672       1.146\n",
       "x7             0.2756      0.019     14.686      0.000       0.239       0.312\n",
       "==============================================================================\n",
       "Omnibus:                       26.324   Durbin-Watson:                   2.049\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               34.560\n",
       "Skew:                          -0.243   Prob(JB):                     3.13e-08\n",
       "Kurtosis:                       3.642   Cond. No.                     1.69e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.69e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5\n",
    "X_opt = X_train[:, [0, 2, 5, 6, 7, 9, 10, 11]]\n",
    "X_opt = np.array(X_opt, dtype=float)\n",
    "\n",
    "regressor_OLS = sm.OLS(endog=y_train, exog=X_opt).fit()\n",
    "regressor_OLS.summary()    # done!\n",
    "# All P < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_acc: 0.30965832743554655\n"
     ]
    }
   ],
   "source": [
    "X_train_opt = X_train[:, [2, 5, 6, 7, 9, 10, 11]]    # select opt's columns\n",
    "X_test_opt = X_test[:, [1, 4, 5, 6, 8, 9, 10]]   # select opt's columns correspond train\n",
    "\n",
    "# do linear regression\n",
    "regressor_opt = LinearRegression()\n",
    "regressor_opt.fit(X_train_opt, y_train)\n",
    "\n",
    "opt_acc = regressor_opt.score(X_test_opt, y_test)\n",
    "print(f\"opt_acc: {opt_acc}\")\n",
    "# qq, maybe not to optimize will better in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
